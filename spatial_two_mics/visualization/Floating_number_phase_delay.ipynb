{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create delays with floating numbers in the input signals\n",
    "### Efthymios Tzinis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import *\n",
    "import librosa\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Customize plots\n",
    "rcParams['figure.figsize'] = (8,4)\n",
    "rcParams['lines.linewidth'] = 1\n",
    "rcParams['axes.axisbelow'] = True\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['font.family'] = 'Avenir Next LT Pro'\n",
    "rcParams['font.weight'] = 400\n",
    "rcParams['xtick.color'] = '#222222'\n",
    "rcParams['ytick.color'] = '#222222'\n",
    "rcParams['grid.color'] = '#dddddd'\n",
    "rcParams['grid.linestyle'] = '-'\n",
    "rcParams['grid.linewidth'] = 0.5\n",
    "rcParams['axes.titlesize'] = 11\n",
    "rcParams['axes.titleweight'] = 600\n",
    "rcParams['axes.labelsize'] = 10\n",
    "rcParams['axes.labelweight'] = 400\n",
    "rcParams['axes.linewidth'] = 0.5\n",
    "rcParams['axes.edgecolor'] = [.25,.25,.25]\n",
    "rcParams['axes.facecolor'] = '#FFFFFF00'\n",
    "rcParams['figure.facecolor'] = '#FFFFFF00'\n",
    "\n",
    "# Decent colormap\n",
    "cdict = {\t'red':   ((0.0,  1.0, 1.0), (1.0,  0.0, 0.0)),\n",
    "\t'green': ((0.0,  1.0, 1.0), (1.0,  .15, .15)),\n",
    "\t\t'blue':  ((0.0,  1.0, 1.0), (1.0,  0.4, 0.4)),\n",
    "\t\t\t'alpha': ((0.0,  0.0, 0.0), (1.0,  1.0, 1.0))}\n",
    "register_cmap(name='InvBlueA', data=cdict)\n",
    "rcParams['image.cmap'] = 'InvBlueA'\n",
    "\n",
    "# Play a sound\n",
    "def soundsc( s, r=16000, name=''):\n",
    "    from IPython.display import display, Audio, HTML\n",
    "    if name is '':\n",
    "        display( Audio( s, rate=r))\n",
    "    else:\n",
    "        display( HTML( \n",
    "        '<style> table, th, td {border: 0px; }</style> <table><tr><td>' + name + \n",
    "        '</td><td>' + Audio( s, rate=r)._repr_html_()[3:] + '</td></tr></table>'\n",
    "        ))\n",
    "\n",
    "# Clean up and redraw\n",
    "def drawnow():\n",
    "    from IPython.display import clear_output\n",
    "    clear_output( wait=True)\n",
    "    show()\n",
    "    \n",
    "# Equal and tight axis\n",
    "def axisequaltight():\n",
    "    gca().set_aspect('equal')\n",
    "    gca().autoscale(tight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from scipy.signal import stft, istft\n",
    "\n",
    "# s1,sr = librosa.core.load( '/mnt/data/timit-wav/test/dr4/flbw0/sa1.wav', sr=None, mono=True)\n",
    "s1,sr = librosa.core.load( '/mnt/data/Speech/timit-wav/test/dr3/mbdg0/sa1.wav', sr=None, mono=True)\n",
    "\n",
    "\n",
    "print(sr)\n",
    "s2,sr = librosa.core.load( '/mnt/data/Speech/timit-wav/test/dr4/mbns0/sa2.wav', sr=None, mono=True)\n",
    "\n",
    "print(sr)\n",
    "\n",
    "s1 = s1[:min(len(s1),len(s2))]\n",
    "s2 = s2[:min(len(s1),len(s2))]\n",
    "\n",
    "soundsc( s1, sr)\n",
    "soundsc( s2, sr)\n",
    "\n",
    "subplot( 2, 1, 1), pcolormesh( abs( stft( s1)[2])**.3)\n",
    "subplot( 2, 1, 2), pcolormesh( abs( stft( s2)[2])**.3)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just in order to check if our loader returns the same\n",
    "import os, sys, librosa, matplotlib, plotly\n",
    "import numpy as np \n",
    "from pprint import pprint \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import FastICA\n",
    "from matplotlib.pyplot import subplot, hist, tight_layout\n",
    "from matplotlib.pylab import title\n",
    "root_dir = '../../'\n",
    "sys.path.insert(0, root_dir)\n",
    "import spatial_two_mics.examples.mixture_example as me\n",
    "import spatial_two_mics.utils.audio_mixture_constructor as mix_constructor\n",
    "import spatial_two_mics.data_generator.source_position_generator as position_generator\n",
    "import spatial_two_mics.labels_inference.tf_label_estimator as label_estimator\n",
    "mixture_info = me.mixture_info_example()\n",
    "\n",
    "random_positioner = position_generator.RandomCirclePositioner()\n",
    "positions_info = random_positioner.get_sources_locations(2)\n",
    "mixture_info['positions'] = positions_info\n",
    "\n",
    "mixture_creator = mix_constructor.AudioMixtureConstructor(\n",
    "        n_fft=512, win_len=512, hop_len=128, mixture_duration=2.0,\n",
    "        force_delays=[-1,1])\n",
    "\n",
    "tf_representations = mixture_creator.construct_mixture(mixture_info)\n",
    "\n",
    "for i, source_tf in enumerate(tf_representations['sources_tf']):\n",
    "    subplot( 2, 1, i+1), pcolormesh( abs(source_tf)**.3)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mixture_info['positions']['thetas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the mixtures\n",
    "s1 = tf_representations['sources_raw'][0]\n",
    "s2 = tf_representations['sources_raw'][1]\n",
    "a = 0.4\n",
    "alphas = [a, 1. - a]\n",
    "tau = 1\n",
    "\n",
    "turbulence = 0.005\n",
    "m1 = alphas[0]*s1[:-tau] + alphas[1]*s2[tau:]\n",
    "m2 = (alphas[0]+turbulence)*s1[tau:] + (alphas[1]-turbulence)*s2[:-tau]\n",
    "m2 = (alphas[0])*s1[tau:] + (alphas[1])*s2[:-tau]\n",
    "\n",
    "n_fft = 512\n",
    "hop_length = 128\n",
    "f1 = librosa.core.stft(m1, n_fft=n_fft, hop_length=hop_length, win_length=n_fft)\n",
    "f2 = librosa.core.stft(m2, n_fft=n_fft, hop_length=hop_length, win_length=n_fft)\n",
    "# f1 = stft(m1)[2]\n",
    "# f2 = stft(m2)[2]\n",
    "\n",
    "# r = log( f1 / (f2+1e-7))\n",
    "r = f1 / (f2+1e-7)\n",
    "\n",
    "# Log amplitude difference\n",
    "a = abs( r)\n",
    "\n",
    "# Phase difference, normalized by frequency\n",
    "p = np.angle( r) / linspace( 1e-5, np.pi, f1.shape[0])[:,None]\n",
    "# p = (np.angle(f1) - np.angle(f2))/ linspace( 1e-5, pi, f1.shape[0])[:,None]\n",
    "# p = (np.angle(f1) - np.angle(f2)) / linspace( 1e-5, pi, f1.shape[0])[:,None]\n",
    "\n",
    "# Show me\n",
    "subplot( 2, 1, 1), hist( a.reshape( -1), linspace( -2, 2, 200)); title( 'Amplitude ratios')\n",
    "subplot( 2, 1, 2), hist( p.reshape( -1), linspace( -pi, pi, 200)); title( 'Normalized phases')\n",
    "# plot(), hist( p.reshape( -1), linspace( -pi, pi, 200)); title( 'Normalized phases')\n",
    "tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hist( p.reshape( -1), linspace( -pi, pi, 200)); title( 'Normalized phases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let us try the same thing but with a randomly provided delay \n",
    "#  for the sources \n",
    "delays_for_sources = positions_info['taus']\n",
    "delays_for_sources = np.array([-0.2, .7])\n",
    "print(delays_for_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the sinc function \n",
    "precision = 0.01\n",
    "freqs_included = 7\n",
    "xs = np.linspace(-freqs_included*sr, freqs_included*sr, \n",
    "                 2.*freqs_included/precision)\n",
    "xs = np.linspace(-freqs_included, freqs_included, \n",
    "                 2.*freqs_included/precision)\n",
    "windowed_sinc = np.sinc(xs)\n",
    "# /(1. * sr)\n",
    "plot(windowed_sinc)\n",
    "title(\"Sinc in time\")\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to convolve this window with all of the but also upsample \n",
    "signal = s1 \n",
    "sig_len = signal.shape[0]\n",
    "n_augmentation_zeros = int(1. / precision) - 1\n",
    "augmented_signal = np.zeros(sig_len + (sig_len-1)*n_augmentation_zeros)\n",
    "augmented_signal[::n_augmentation_zeros+1] = signal\n",
    "\n",
    "print(n_augmentation_zeros)     \n",
    "print(sig_len)\n",
    "subplot( 2, 1, 1), plot(signal[:15])\n",
    "subplot( 2, 1, 2), plot(augmented_signal[:15*(n_augmentation_zeros+1)])\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the convolution with the augmented signal after zero padding \n",
    "est_augmented_sig = np.convolve(augmented_signal, windowed_sinc, mode='valid')\n",
    "subplot( 2, 1, 1), plot(signal)\n",
    "subplot( 2, 1, 2), plot(est_augmented_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to make sure resample in order to check the initila signal the initial signal \n",
    "reconstructed_sig = est_augmented_sig[::n_augmentation_zeros+1]\n",
    "\n",
    "subplot( 4, 1, 1), plot(signal[freqs_included:3*freqs_included])\n",
    "subplot( 4, 1, 2), plot(augmented_signal[freqs_included*(n_augmentation_zeros+1):3*freqs_included*(n_augmentation_zeros+1)])\n",
    "subplot( 4, 1, 3), plot(est_augmented_sig[:2*freqs_included*(n_augmentation_zeros+1)])\n",
    "subplot( 4, 1, 4), plot(reconstructed_sig[:2*freqs_included]) #; title(\"Reconstructed after augmentation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now in order to make the delay we have the augmented signal \n",
    "# so we round the delays up to a specific precision we have selected \n",
    "decimals = int(np.log10(1. / precision))\n",
    "rounded_taus = np.around(delays_for_sources, decimals=decimals)\n",
    "print(decimals)\n",
    "print(rounded_taus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples needed to be rotated over the time axis in order to meet the delays that are generated \n",
    "taus_samples = int(1./precision) * rounded_taus\n",
    "taus_samples = taus_samples.astype(int)\n",
    "print(taus_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now in case of a positive delay we would have to forward the signal in the first microphone \n",
    "# or delay it otherwise by the number of samples that is defined for the corresponding source\n",
    "source_signals = [s1, s1]\n",
    "upsampling_rate = int(1. / precision)\n",
    "n_augmentation_zeros = upsampling_rate - 1\n",
    "\n",
    "mics_sources = [[], []]\n",
    "for src_id, source_sig in enumerate(source_signals):\n",
    "    sig_len = source_sig.shape[0]\n",
    "    augmented_signal = np.zeros(int(sig_len + (sig_len-1)*n_augmentation_zeros))\n",
    "    augmented_signal[::n_augmentation_zeros+1] = source_sig\n",
    "    \n",
    "    tau_in_samples = taus_samples[src_id]\n",
    "    if tau_in_samples > 0:\n",
    "        mics_sources[0].append(est_augmented_sig[tau_in_samples:][::upsampling_rate])\n",
    "        mics_sources[1].append(est_augmented_sig[:-tau_in_samples][::upsampling_rate])\n",
    "    elif tau_in_samples < 0:\n",
    "        mics_sources[0].append(est_augmented_sig[-tau_in_samples:][::upsampling_rate])\n",
    "        mics_sources[1].append(est_augmented_sig[:tau_in_samples][::upsampling_rate])\n",
    "    else:        \n",
    "        mics_sources[0].append(est_augmented_sig[::upsampling_rate])\n",
    "        mics_sources[1].append(est_augmented_sig[::upsampling_rate])\n",
    "\n",
    "for mic_ind, mic_sources_list in enumerate(mics_sources):\n",
    "    print(len(mic_sources_list[0]))\n",
    "    print(len(mic_sources_list[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's write it in a proper function \n",
    "def enforce_float_delays(source_signals,  \n",
    "                         delays_for_sources,\n",
    "                         fs, \n",
    "                         precision=0.01, \n",
    "                         duration=2.0, \n",
    "                         freqs_included = 5):\n",
    "    \"\"\"!\n",
    "    For 2 microphone enforce a floating point number delay with some selected precision and\n",
    "    apply that for all sources that would be given. Also make sure that the required to be \n",
    "    returned wavs have to have a length equal to the duration\"\"\"\n",
    "    upsampling_rate = int(1. / precision)\n",
    "    duration_in_samples = int(duration * fs)\n",
    "    decimals = int(np.log10(upsampling_rate))\n",
    "    \n",
    "    rounded_taus = np.around(delays_for_sources, decimals=decimals)\n",
    "    taus_samples = upsampling_rate * rounded_taus\n",
    "    taus_samples = taus_samples.astype(int)\n",
    "    \n",
    "    print(taus_samples)\n",
    "    \n",
    "    xs = np.linspace(-freqs_included, freqs_included, \n",
    "                     2.*freqs_included/precision)\n",
    "    windowed_sinc = np.sinc(xs)\n",
    "    \n",
    "    mics_sources = [[], []]\n",
    "    for src_id, source_sig in enumerate(source_signals):\n",
    "        sig_len = source_sig.shape[0]\n",
    "        augmented_signal = np.zeros(sig_len + (sig_len-1)*n_augmentation_zeros)\n",
    "        augmented_signal[::upsampling_rate] = source_sig\n",
    "        est_augmented_sig = np.convolve(augmented_signal, \n",
    "                                        windowed_sinc, \n",
    "                                        mode='valid')\n",
    "\n",
    "        tau_in_samples = taus_samples[src_id]\n",
    "        if tau_in_samples > 0:\n",
    "            source_in_mic1 = est_augmented_sig[\n",
    "                             tau_in_samples:][::upsampling_rate]\n",
    "            source_in_mic2 = est_augmented_sig[\n",
    "                             :-tau_in_samples][::upsampling_rate]\n",
    "        elif tau_in_samples < 0:\n",
    "            source_in_mic1 = est_augmented_sig[\n",
    "                             :tau_in_samples][::upsampling_rate]\n",
    "            source_in_mic2 = est_augmented_sig[\n",
    "                             -tau_in_samples:][::upsampling_rate]\n",
    "        else:\n",
    "            source_in_mic1 = est_augmented_sig[::upsampling_rate]\n",
    "            source_in_mic2 = est_augmented_sig[::upsampling_rate]\n",
    "            \n",
    "        # check the duration which is very important \n",
    "        if (len(source_in_mic1) < duration_in_samples or  \n",
    "            len(source_in_mic2) < duration_in_samples):\n",
    "            raise ValueError(\"Duration given: {} could \"\n",
    "                  \"not be sufficed before the gven source\"\n",
    "                  \" signal has a lesser duration of {} \"\n",
    "                  \"after the float delay.\".format(\n",
    "                  duration_in_samples, len(source_in_mic1)))\n",
    "            \n",
    "        mics_sources[0].append(source_in_mic1[:duration_in_samples])\n",
    "        mics_sources[1].append(source_in_mic2[:duration_in_samples])\n",
    "    \n",
    "    return mics_sources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = tf_representations['sources_raw'][0]\n",
    "s2 = tf_representations['sources_raw'][1]\n",
    "print(delays_for_sources)\n",
    "mics_sources = enforce_float_delays([s1, s2], delays_for_sources,\n",
    "                                    16000, duration=1.9, freqs_included=7, precision=0.01)\n",
    "pprint(mics_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's see how the phase changes from the previous no delay version \n",
    "m1 = alphas[0]*mics_sources[0][0] + alphas[1]*mics_sources[0][1]\n",
    "m2 = alphas[0]*mics_sources[1][0] + alphas[1]*mics_sources[1][1]\n",
    "\n",
    "n_fft = 512\n",
    "hop_length = 128\n",
    "f1_f_delayed = librosa.core.stft(m1, n_fft=n_fft, hop_length=hop_length, win_length=n_fft)\n",
    "f2_f_delayed = librosa.core.stft(m2, n_fft=n_fft, hop_length=hop_length, win_length=n_fft)\n",
    "# f1 = stft(m1)[2]\n",
    "# f2 = stft(m2)[2]\n",
    "\n",
    "# r = log( f1 / (f2+1e-7))\n",
    "r_f_delayed = f1_f_delayed / (f2_f_delayed+1e-7)\n",
    "\n",
    "# Log amplitude difference\n",
    "a_f_delayed = abs( r_f_delayed)\n",
    "\n",
    "# Phase difference, normalized by frequency\n",
    "p_f_delayed = np.angle( r_f_delayed) / linspace( 1e-5, np.pi, f1_f_delayed.shape[0])[:,None]\n",
    "# p = (np.angle(f1) - np.angle(f2))/ linspace( 1e-5, pi, f1.shape[0])[:,None]\n",
    "# p = (np.angle(f1) - np.angle(f2)) / linspace( 1e-5, pi, f1.shape[0])[:,None]\n",
    "\n",
    "# Show me\n",
    "subplot( 2, 2, 1), hist( a.reshape( -1), linspace( -2, 2, 200)); title( '[-1, 1] delays Amplitude ratios')\n",
    "subplot( 2, 2, 2), hist( p.reshape( -1), linspace( -pi, pi, 200)); title( '[-1, 1] delays Normalized phases')\n",
    "\n",
    "subplot( 2, 2, 3), hist( a_f_delayed.reshape( -1), linspace( -2, 2, 200)); title( \n",
    "                   '{} delays Amplitude ratios'.format(rounded_taus))\n",
    "subplot( 2, 2, 4), hist( p_f_delayed.reshape( -1), linspace( -pi, pi, 200)); title( \n",
    "                   '{} delays Normalized phases'.format(rounded_taus))\n",
    "# plot(), hist( p.reshape( -1), linspace( -pi, pi, 200)); title( 'Normalized phases')\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly Functions \n",
    "import plotly\n",
    "import plotly.tools as tls\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_tf_representation(tf, for_title = '', fs=16000, duration=2.0, log_scale=False):\n",
    "    freq_max, time_max = tf.shape\n",
    "    bins = np.arange(time_max)\n",
    "    bins = (duration * bins) / time_max \n",
    "    freqs = np.arange(freq_max)\n",
    "    freqs = (freqs * fs) / (2.0 * freq_max) \n",
    "    trace = [go.Heatmap(\n",
    "        x= bins,\n",
    "        y= freqs,\n",
    "#         z= 10*np.log10(Pxx),\n",
    "        z = 10*np.log10(tf) if log_scale else tf,\n",
    "        colorscale='Jet',\n",
    "        )]\n",
    "    layout = go.Layout(\n",
    "        title = 'Spectrogram '+for_title,\n",
    "        yaxis = dict(title = 'Frequency'), # x-axis label\n",
    "        xaxis = dict(title = 'Time'), # y-axis label\n",
    "        )\n",
    "    fig = dict(data=trace, layout=layout)\n",
    "    plotly.offline.iplot(fig, filename=for_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's check how these features go compared to the ground truth mask \n",
    "ground_truth_estimator = label_estimator.TFMaskEstimator(\n",
    "                             inference_method='Ground_truth') \n",
    "tf_representations['amplitudes'] = alphas \n",
    "tf_representations['sources_tf'] = [librosa.core.stft(mics_sources[0][0], n_fft=n_fft, \n",
    "                                                      hop_length=hop_length, win_length=n_fft), \n",
    "                                    librosa.core.stft(mics_sources[0][1], n_fft=n_fft, \n",
    "                                                      hop_length=hop_length, win_length=n_fft)]\n",
    "gt_labels = ground_truth_estimator.infer_mixture_labels(tf_representations)\n",
    "plot_tf_representation(gt_labels, for_title = 'Ground Truth Mask', log_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustKmeans(object):\n",
    "    def __init__(self,\n",
    "                 n_true_clusters=2,\n",
    "                 n_used_clusters=4):\n",
    "        \"\"\"!\n",
    "        Sometimes K-means creates clusters around outlier groups which\n",
    "        should not be the case. For this reason we run K-means with\n",
    "        n_used_clusters > n_true_clusters and then we assign at the most\n",
    "        probable n_true_clusters the residual clusters\n",
    "\n",
    "        :param n_true_clusters: the true number of clusters we wanna\n",
    "        cluster the data at the end\n",
    "        :param n_used_clusters: The amount of clusters that will be used\n",
    "        in total for running kmeans and after that the residual would be\n",
    "        assigned in the top most prior n_true_clusters\n",
    "        \"\"\"\n",
    "\n",
    "        self.N_true = n_true_clusters\n",
    "        self.N_used = n_used_clusters\n",
    "        self.kmeans_obj = KMeans(n_clusters=self.N_used,\n",
    "                                 random_state=7)\n",
    "\n",
    "    def fit(self, x, cut_outlier_in_norm=2.):\n",
    "        \"\"\"!\n",
    "        robust clustering for the input x\n",
    "\n",
    "        :param x: nd array with shape: (n_samples, n_features)\n",
    "\n",
    "        :return cluster_labels: 1d array with the corresponding\n",
    "        labels from 0 to self.N_true - 1\n",
    "        \"\"\"\n",
    "        \n",
    "        if cut_outlier_in_norm is not None:\n",
    "            robust_estimators = d_feature[\n",
    "            np.where(np.abs(x)<= cut_outlier_in_norm)].reshape(-1, 1)\n",
    "            \n",
    "            fitted_to_estimators = self.kmeans_obj.fit(robust_estimators)\n",
    "            clustered = self.kmeans_obj.predict(d_feature)\n",
    "        else:\n",
    "            fitted_to_estimators = self.kmeans_obj.fit(x)\n",
    "            clustered = fitted_to_estimators.labels_\n",
    "        \n",
    "        cluster_coordinates = fitted_to_estimators.cluster_centers_\n",
    "        \n",
    "        priors = np.bincount(clustered)\n",
    "                \n",
    "        cl_indexes = np.argsort(priors)\n",
    "        residual_clusters = cl_indexes[:-self.N_true]\n",
    "\n",
    "        true_clusters = cl_indexes[self.N_used-self.N_true:]\n",
    "        \n",
    "        fitted_to_estimators.cluster_centers_ = cluster_coordinates[true_clusters]\n",
    "        \n",
    "#         make the new prediction with the new clusters\n",
    "        \n",
    "        robust_estimation = fitted_to_estimators.predict(d_feature)\n",
    "        \n",
    "#         cluster_identity = dict([(i, k)\n",
    "#                                  for k, i in enumerate(true_clusters)])\n",
    "#         top_prior = cluster_identity[cl_indexes[-1]]\n",
    "\n",
    "#         cluster_changer = dict([(i, top_prior)\n",
    "#                                 for i in residual_clusters])\n",
    "#         cluster_changer.update(cluster_identity)\n",
    "\n",
    "#         robust_clustered = [cluster_changer[cl_ind]\n",
    "#                             for cl_ind in clustered]\n",
    "\n",
    "#         robust_estimation = np.array(robust_clustered)\n",
    "        \n",
    "        return robust_estimation\n",
    "    \n",
    "    def semi_noob_fit(self, x, cut_outlier_in_norm=2.):\n",
    "        \"\"\"!\n",
    "        robust clustering for the input x\n",
    "\n",
    "        :param x: nd array with shape: (n_samples, n_features)\n",
    "\n",
    "        :return cluster_labels: 1d array with the corresponding\n",
    "        labels from 0 to self.N_true - 1\n",
    "        \"\"\"\n",
    "        \n",
    "        if cut_outlier_in_norm is not None:\n",
    "            robust_estimators = d_feature[\n",
    "            np.where(np.abs(x)<= cut_outlier_in_norm)].reshape(-1, 1)\n",
    "            \n",
    "            fitted_to_estimators = self.kmeans_obj.fit(robust_estimators)\n",
    "            clustered = self.kmeans_obj.predict(d_feature)\n",
    "        else:\n",
    "            fitted_to_estimators = self.kmeans_obj.fit(x)\n",
    "            clustered = fitted_to_estimators.labels_\n",
    "        \n",
    "        cluster_coordinates = fitted_to_estimators.cluster_centers_\n",
    "        \n",
    "        priors = np.bincount(clustered)\n",
    "                \n",
    "        cl_indexes = np.argsort(priors)\n",
    "        residual_clusters = cl_indexes[:-self.N_true]\n",
    "\n",
    "        true_clusters = cl_indexes[self.N_used-self.N_true:]\n",
    "        \n",
    "#         fitted_to_estimators.cluster_centers_ = cluster_coordinates[true_clusters]\n",
    "        \n",
    "#         make the new prediction with the new clusters\n",
    "        \n",
    "#         robust_estimation = fitted_to_estimators.predict(d_feature)\n",
    "        \n",
    "        cluster_identity = dict([(i, k)\n",
    "                                 for k, i in enumerate(true_clusters)])\n",
    "        top_prior = cluster_identity[cl_indexes[-1]]\n",
    "\n",
    "        cluster_changer = dict([(i, top_prior)\n",
    "                                for i in residual_clusters])\n",
    "        cluster_changer.update(cluster_identity)\n",
    "\n",
    "        robust_clustered = [cluster_changer[cl_ind]\n",
    "                            for cl_ind in clustered]\n",
    "\n",
    "        robust_estimation = np.array(robust_clustered)\n",
    "        \n",
    "        return robust_estimation\n",
    "    \n",
    "    \n",
    "    def noob_fit(self, x):\n",
    "        \"\"\"!\n",
    "        robust clustering for the input x\n",
    "\n",
    "        :param x: nd array with shape: (n_samples, n_features)\n",
    "\n",
    "        :return cluster_labels: 1d array with the corresponding\n",
    "        labels from 0 to self.N_true - 1\n",
    "        \"\"\"\n",
    "\n",
    "        clustered = self.kmeans_obj.fit(x).labels_\n",
    "        priors = np.bincount(clustered)\n",
    "        cl_indexes = np.argsort(priors)\n",
    "        residual_clusters = cl_indexes[:-self.N_true]\n",
    "\n",
    "        true_clusters = cl_indexes[self.N_used-self.N_true:]\n",
    "        cluster_identity = dict([(i, k)\n",
    "                                 for k, i in enumerate(true_clusters)])\n",
    "        top_prior = cluster_identity[cl_indexes[-1]]\n",
    "\n",
    "        cluster_changer = dict([(i, top_prior)\n",
    "                                for i in residual_clusters])\n",
    "        cluster_changer.update(cluster_identity)\n",
    "\n",
    "        robust_clustered = [cluster_changer[cl_ind]\n",
    "                            for cl_ind in clustered]\n",
    "\n",
    "        return np.array(robust_clustered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now perform the analysis for duet soft labeling\n",
    "phase_dif = p_f_delayed\n",
    "n_sources = len(tf_representations['sources_tf'])\n",
    "d_feature = np.reshape(phase_dif, (np.product(phase_dif.shape), 1))\n",
    "\n",
    "used_clusters = 5\n",
    "r_kmeans = RobustKmeans(n_true_clusters=2, n_used_clusters=used_clusters)\n",
    "# kmeans = KMeans(n_clusters=clusters, random_state=7).fit(d_feature)\n",
    "\n",
    "d_labels = r_kmeans.noob_fit(d_feature)\n",
    "d_feature_mask = np.reshape(d_labels, phase_dif.shape)\n",
    "plot_tf_representation(d_feature_mask, \n",
    "                       for_title = ' Phase Diff only using Noob Robust {}-means => 2 clusters'.format(used_clusters), \n",
    "                       log_scale=False)\n",
    "\n",
    "d_labels = r_kmeans.semi_noob_fit(d_feature)\n",
    "d_feature_mask = np.reshape(d_labels, phase_dif.shape)\n",
    "plot_tf_representation(d_feature_mask, \n",
    "                       for_title = ' Phase Diff only using Smei Noob Robust {}-means => 2 clusters'.format(used_clusters), \n",
    "                       log_scale=False)\n",
    "\n",
    "d_labels = r_kmeans.fit(d_feature)\n",
    "d_feature_mask = np.reshape(d_labels, phase_dif.shape)\n",
    "plot_tf_representation(d_feature_mask, \n",
    "                       for_title = ' Phase Diff only using Ooutlier Robust {}-means => 2 clusters'.format(used_clusters), \n",
    "                       log_scale=False)\n",
    "# print(d_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tf_representation(gt_labels, for_title = 'Ground Truth Mask', log_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the duet features how they scatter \n",
    "attenuation = abs(r_f_delayed)\n",
    "smoothed_attenuation = attenuation - (1. / attenuation)\n",
    "smoothed_attenuation_feature = np.reshape(smoothed_attenuation, (np.product(smoothed_attenuation.shape), 1))\n",
    "duet_features = np.concatenate((d_feature, smoothed_attenuation_feature), axis=1)\n",
    "\n",
    "gt_flatten = gt_labels.reshape(1,-1)\n",
    "xyl = np.concatenate((duet_features, gt_flatten.T), axis=1) \n",
    "\n",
    "# clip high norm values and also random sampling\n",
    "xyl = np.clip(xyl, -1., 1.)\n",
    "rand_ind = np.random.choice(np.arange(xyl.shape[0]), size=3000, replace=False)\n",
    "xyl = xyl[rand_ind, :]\n",
    "\n",
    "\n",
    "N = xyl.shape[0]\n",
    "pred0 = xyl[xyl[:,2]==0]\n",
    "pred1 = xyl[xyl[:,2]==1]\n",
    "\n",
    "title = 'Scatter of DUET features for Ground Truth Masking'\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x = pred0[:,0],\n",
    "    y = pred0[:,1],\n",
    "    name = 'Source 1',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 5,\n",
    "        color = 'rgba(152, 0, 0, .8)',\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "            color = 'rgb(0, 0, 0)'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = pred1[:,0],\n",
    "    y = pred1[:,1],\n",
    "    name = 'Source 2',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 5,\n",
    "        color = 'rgba(255, 182, 193, .9)',\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# also check the clusters from Kmeas \n",
    "kmeans_sol = KMeans(n_clusters=used_clusters, random_state=7).fit(d_feature)\n",
    "clusters_xy = kmeans_sol.cluster_centers_\n",
    "print(clusters_xy)\n",
    "print(d_feature.max())\n",
    "cluster_traces = []\n",
    "for cl_ind in np.arange(clusters_xy.shape[0]):\n",
    "    x_cl = clusters_xy[cl_ind]\n",
    "    trace_cl = go.Scatter(\n",
    "        x = x_cl,\n",
    "        y = [0.],\n",
    "        name = 'Cluster {}'.format(cl_ind + 1),\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = 10,\n",
    "            symbol = 'x-open',\n",
    "            line = dict(\n",
    "                width = 4,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    cluster_traces.append(trace_cl)\n",
    "    \n",
    "\n",
    "data = [trace0, trace1] + cluster_traces\n",
    "\n",
    "layout = dict(title = 'Scatter for Robust kmeans using many clusters',\n",
    "              yaxis = dict(zeroline = False, title='Attenuation'),\n",
    "              xaxis = dict(zeroline = False, title = 'Phase Difference')\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "plotly.offline.iplot(fig, filename=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.5, 0.5]\n",
    "m1 = alphas[0]*mics_sources[0][0] + alphas[1]*mics_sources[0][1]\n",
    "m2 = alphas[0]*mics_sources[1][0] + alphas[1]*mics_sources[1][1]\n",
    "\n",
    "n_fft = 512\n",
    "hop_length = 128\n",
    "f1_f_delayed = librosa.core.stft(m1, n_fft=n_fft, hop_length=hop_length, win_length=n_fft)\n",
    "f2_f_delayed = librosa.core.stft(m2, n_fft=n_fft, hop_length=hop_length, win_length=n_fft)\n",
    "# f1 = stft(m1)[2]\n",
    "# f2 = stft(m2)[2]\n",
    "\n",
    "# r = log( f1 / (f2+1e-7))\n",
    "r_f_delayed = f1_f_delayed / (f2_f_delayed+1e-7)\n",
    "\n",
    "# Log amplitude difference\n",
    "a_f_delayed = abs( r_f_delayed)\n",
    "\n",
    "# Phase difference, normalized by frequency\n",
    "p_f_delayed = np.angle( r_f_delayed) / linspace( 1e-5, np.pi, f1_f_delayed.shape[0])[:,None]\n",
    "\n",
    "phase_dif = p_f_delayed\n",
    "n_sources = 2\n",
    "d_feature = np.reshape(phase_dif, (np.product(phase_dif.shape), 1))\n",
    "\n",
    "gt_flatten = gt_labels.reshape(1,-1)\n",
    "xyl = np.concatenate((d_feature, gt_flatten.T), axis=1) \n",
    "d_feature = np.clip(d_feature, -1., 1.)\n",
    "\n",
    "pd1 = d_feature[xyl[:,1]==0][:,0]\n",
    "pd2 = d_feature[xyl[:,1]==1][:,0]\n",
    "\n",
    "pd1 = pd1[np.where( (pd1 < 1.0)  & (pd1 > -1.0) & (pd1 != 0.) )]\n",
    "normalized_pd1 = pd1 / pd1.sum()\n",
    "\n",
    "pd2 = pd2[np.where( (pd2 < 1.0)  & (pd2 > -1.0) & (pd2 != 0.))]\n",
    "normalized_pd2 = pd2 / pd2.sum()\n",
    "\n",
    "\n",
    "trace1 = go.Histogram(\n",
    "    x=pd1,\n",
    "    opacity=0.99,\n",
    "    name='Speaker A: -0.2 NPD   ',\n",
    "    xbins=dict(\n",
    "        size=0.02\n",
    "    )\n",
    ")\n",
    "trace2 = go.Histogram(\n",
    "    x=pd2,\n",
    "    opacity=0.6,\n",
    "    name='Speaker B: 0.7 NPD    ',\n",
    "    xbins=dict(\n",
    "        size=0.02\n",
    "    )\n",
    ")\n",
    "\n",
    "width = 1000 \n",
    "height = 600\n",
    "\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(barmode='overlay', \n",
    "                   showlegend=True,\n",
    "                   width = width, \n",
    "                   height = height,\n",
    "                   margin = go.layout.Margin(\n",
    "#                    l=0,\n",
    "                   r=5,\n",
    "                   t=0,\n",
    "                   b=60,\n",
    "#                    pad=0\n",
    "                   ),\n",
    "                   \n",
    "                   legend=dict(\n",
    "                        x=0.02,\n",
    "                        y=0.95,\n",
    "                        traceorder='normal',\n",
    "                        font=dict(\n",
    "                            family='sans-serif',\n",
    "                            size=20,\n",
    "                            color='#000'\n",
    "                        ),\n",
    "                        bgcolor='rgb(255,255,255)'\n",
    "#                         bgcolor='#E2E2E2',\n",
    "#                         bordercolor='#FFFFFF',\n",
    "#                         borderwidth=3\n",
    "                    ),\n",
    "                   yaxis = dict(zeroline = False, title='STFT Bins Count',\n",
    "                                tickfont=dict(\n",
    "                                    family='Old Standard TT, serif',\n",
    "                                    size=24,\n",
    "                                    color='black'\n",
    "                                ),\n",
    "                               titlefont=dict(\n",
    "                                    size=24,\n",
    "                                    family='Old Standard TT, serif',\n",
    "                                    color='black',\n",
    "                                )),\n",
    "                   xaxis = dict(zeroline = False, title = 'Normalized Phase Difference (NPD)',\n",
    "                               titlefont=dict(\n",
    "                                    family='Old Standard TT, serif',\n",
    "                                    color='black',\n",
    "                                    size=24,\n",
    "                                ),\n",
    "                               tickfont=dict(\n",
    "                                    family='Old Standard TT, serif',\n",
    "                                    size=24,\n",
    "                                    color='black'\n",
    "                                ))\n",
    "                  )\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "plotly.offline.iplot(fig, filename='npd_paper', \n",
    "                     image_width= width,\n",
    "                      image_height = height, \n",
    "                     image='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tf_representation(p_f_delayed, \n",
    "                       for_title = ' Phase Difference', \n",
    "                       log_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an even more robust k-means \n",
    "# print(p_f_delayed.shape)\n",
    "# print(np.abs(p_f_delayed).max())\n",
    "# print(np.unravel_index(np.abs(p_f_delayed).argmax(), p_f_delayed.shape))\n",
    "# outlier_mask = np.where(np.abs(d_feature)>1.)\n",
    "abs_diff = np.abs(d_feature)\n",
    "robust_estimators = d_feature[np.where(abs_diff<= 2.)].reshape(-1, 1)\n",
    "\n",
    "# print(np.mean(robust_estimators))\n",
    "\n",
    "# robust_estimators = d_feature[np.where(abs_diff - np.mean(abs_diff)<= 0.01 * np.std(abs_diff))].reshape(-1, 1)\n",
    "# outliers = d_feature[outlier_mask]\n",
    "# create the clustering by throwing away the outliers\n",
    "kmeans_sol = KMeans(n_clusters=2, random_state=7).fit(robust_estimators)\n",
    "robust_d_pred = kmeans_sol.predict(d_feature).reshape(phase_dif.shape)\n",
    "print(d_feature.shape)\n",
    "print(robust_d_pred.shape)\n",
    "# .reshape(phase_dif.shape)\n",
    "plot_tf_representation(robust_d_pred, \n",
    "                       for_title = ' Phase Diff only using Outlier Robust 2-means =>',\n",
    "                       log_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## from sklearn import cluster, datasets, mixture\n",
    "# from sklearn.neighbors import kneighbors_graph\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from itertools import cycle, islice \n",
    "\n",
    "# attenuation = abs(r_f_delayed)\n",
    "# smoothed_attenuation = attenuation - (1. / attenuation)\n",
    "# smoothed_attenuation_feature = np.reshape(smoothed_attenuation, (np.product(smoothed_attenuation.shape), 1))\n",
    "# duet_features = np.concatenate((d_feature, smoothed_attenuation_feature), axis=1)\n",
    "\n",
    "# used_clusters = 3\n",
    "# r_kmeans = robust_kmeans.RobustKmeans(n_true_clusters=2, n_used_clusters=used_clusters)\n",
    "# # kmeans = KMeans(n_clusters=clusters, random_state=7).fit(d_feature)\n",
    "# duet_labels = r_kmeans.fit(duet_features)\n",
    "# duet_mask = np.reshape(duet_labels, phase_dif.shape)\n",
    "# plot_tf_representation(duet_mask, \n",
    "#                        for_title = ' DUET features using Robust {}-means => 2 clusters'.format(used_clusters), \n",
    "#                        log_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the duet features how they scatter \n",
    "gt_flatten = gt_labels.reshape(1,-1)\n",
    "xyl = np.concatenate((duet_features, gt_flatten.T), axis=1) \n",
    "\n",
    "# clip high norm values and also random sampling\n",
    "xyl = np.clip(xyl, -1., 1.)\n",
    "rand_ind = np.random.choice(np.arange(xyl.shape[0]), size=3000, replace=False)\n",
    "xyl = xyl[rand_ind, :]\n",
    "\n",
    "\n",
    "N = xyl.shape[0]\n",
    "pred0 = xyl[xyl[:,2]==0]\n",
    "pred1 = xyl[xyl[:,2]==1]\n",
    "\n",
    "title = 'Scatter of DUET features for Ground Truth Masking'\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x = pred0[:,0],\n",
    "    y = pred0[:,1],\n",
    "    name = 'Source 1',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 5,\n",
    "        color = 'rgba(152, 0, 0, .8)',\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "            color = 'rgb(0, 0, 0)'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "trace1 = go.Scatter(\n",
    "    x = pred1[:,0],\n",
    "    y = pred1[:,1],\n",
    "    name = 'Source 2',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 5,\n",
    "        color = 'rgba(255, 182, 193, .9)',\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# also check the clusters from Kmeans \n",
    "clusters_xy = kmeans_sol.cluster_centers_\n",
    "print(clusters_xy)\n",
    "print(d_feature.max())\n",
    "cluster_traces = []\n",
    "for cl_ind in np.arange(clusters_xy.shape[0]):\n",
    "    x_cl = clusters_xy[cl_ind]\n",
    "    trace_cl = go.Scatter(\n",
    "        x = x_cl,\n",
    "        y = [0.],\n",
    "        name = 'Cluster {}'.format(cl_ind + 1),\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = 10,\n",
    "            line = dict(\n",
    "                width = 4,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    cluster_traces.append(trace_cl)\n",
    "    \n",
    "\n",
    "data = [trace0, trace1] + cluster_traces\n",
    "\n",
    "layout = dict(title = 'Styled Scatter',\n",
    "              yaxis = dict(zeroline = False, title='Attenuation'),\n",
    "              xaxis = dict(zeroline = False, title = 'Phase Difference')\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "plotly.offline.iplot(fig, filename=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now run multiple clustering algorithms in order to see how it goes:\n",
    "# gmm = mixture.GaussianMixture(\n",
    "#       n_components=n_sources, covariance_type='full')\n",
    "# spectral = cluster.SpectralClustering(\n",
    "#         n_clusters=n_sources, eigen_solver='arpack',\n",
    "#         affinity=\"nearest_neighbors\")\n",
    "# kmeans = KMeans(n_clusters=n_sources, random_state=0)\n",
    "\n",
    "# clustering_algorithms = (\n",
    "#         ('Kmeans', kmeans),\n",
    "#         ('SpectralClustering', spectral),\n",
    "#         ('GaussianMixture', gmm)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_representation(mask, gt, for_title, fs=16000., \n",
    "                            log_scale=False):\n",
    "    freq_max, time_max = mask.shape\n",
    "    bins = np.arange(time_max)\n",
    "    bins = (duration * bins) / time_max \n",
    "    freqs = np.arange(freq_max)\n",
    "    freqs = (freqs * fs) / (2.0 * freq_max) \n",
    "    trace = [go.Heatmap(\n",
    "        x= bins,\n",
    "        y= freqs,\n",
    "        z = 10*np.log10(mask) if log_scale else mask,\n",
    "        colorscale='Jet',\n",
    "        )]\n",
    "#     also plot the difference from the true mask \n",
    "    trace2 = [go.Heatmap(\n",
    "        x= bins,\n",
    "        y= freqs,\n",
    "        z = abs(mask-gt),\n",
    "        colorscale='Jet',\n",
    "        )]\n",
    "    \n",
    "    layout = go.Layout(\n",
    "        title = for_title,\n",
    "        yaxis = dict(title = 'Frequency'), # x-axis label\n",
    "        xaxis = dict(title = 'Time'), # y-axis label\n",
    "        )\n",
    "    fig = dict(data=trace, layout=layout)\n",
    "    plotly.offline.iplot(fig, filename=for_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X = duet_features\n",
    "# plot_num = 1\n",
    "# for name, algorithm in clustering_algorithms:\n",
    "#     t0 = time.time()\n",
    "\n",
    "#     # catch warnings related to kneighbors_graph\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.filterwarnings(\n",
    "#             \"ignore\",\n",
    "#             message=\"the number of connected components of the \" +\n",
    "#             \"connectivity matrix is [0-9]{1,2}\" +\n",
    "#             \" > 1. Completing it to avoid stopping the tree early.\",\n",
    "#             category=UserWarning)\n",
    "#         warnings.filterwarnings(\n",
    "#             \"ignore\",\n",
    "#             message=\"Graph is not fully connected, spectral embedding\" +\n",
    "#             \" may not work as expected.\",\n",
    "#             category=UserWarning)\n",
    "#         algorithm.fit(X)\n",
    "\n",
    "#     t1 = time.time()\n",
    "#     if hasattr(algorithm, 'labels_'):\n",
    "#         y_pred = algorithm.labels_\n",
    "#     else:\n",
    "#         y_pred = algorithm.predict(X)\n",
    "    \n",
    "#     duet_mask = np.reshape(y_pred, phase_dif.shape)\n",
    "#     title = 'Algorithm: {} run in {} seconds'.format(name, t1-t0 )\n",
    "# #     plot_tf_representation(duet_mask, gt_labels, title, log_scale=False)\n",
    "#     plot_tf_representation(duet_mask, for_title=title, log_scale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bss_eval( sep, i, sources):\n",
    "    # Current target\n",
    "    from numpy import dot, linalg, log10\n",
    "    min_len = min([len(sep), len(sources[i])])\n",
    "    sources = sources[:,:min_len]\n",
    "    sep = sep[:min_len]\n",
    "    target = sources[i]\n",
    "\n",
    "    # Target contribution\n",
    "    s_target = target * dot( target, sep.T) / dot( target, target.T)\n",
    "\n",
    "    # Interference contribution\n",
    "    pse = dot( dot( sources, sep.T), \\\n",
    "    linalg.inv( dot( sources, sources.T))).T.dot( sources)\n",
    "    e_interf = pse - s_target\n",
    "\n",
    "    # Artifact contribution\n",
    "    e_artif= sep - pse;\n",
    "\n",
    "    # Interference + artifacts contribution\n",
    "    e_total = e_interf + e_artif;\n",
    "\n",
    "    # Computation of the log energy ratios\n",
    "    sdr = 10*log10( sum( s_target**2) / sum( e_total**2));\n",
    "    sir = 10*log10( sum( s_target**2) / sum( e_interf**2));\n",
    "    sar = 10*log10( sum( (s_target + e_interf)**2) / sum( e_artif**2));\n",
    "\n",
    "    return (sdr, sir, sar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# try to evaluate the reconstructed signals \n",
    "d_feature = np.reshape(phase_dif, (np.product(phase_dif.shape), 1))\n",
    "\n",
    "r_kmeans = robust_kmeans.RobustKmeans(n_true_clusters=2, n_used_clusters=used_clusters)\n",
    "# kmeans = KMeans(n_clusters=clusters, random_state=7).fit(d_feature)\n",
    "duet_labels = r_kmeans.fit(d_feature)\n",
    "duet_mask = np.reshape(duet_labels, phase_dif.shape)\n",
    "gt_mask = gt_labels \n",
    "\n",
    "for i in np.arange(n_sources):\n",
    "    d_stft = abs(f1_f_delayed)*(duet_mask==i).reshape(f1_f_delayed.shape)\n",
    "    gt_stft = abs(f1_f_delayed)*(gt_mask==i).reshape(f1_f_delayed.shape)\n",
    "    plot_tf_representation(d_stft, for_title='Duet reconstructed STFT')\n",
    "    plot_tf_representation(gt_stft, for_title='Ground truth reconstructed STFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_rec = []\n",
    "stft_gt = []\n",
    "\n",
    "sources = np.array([s1, s2])\n",
    "# sources = np.array([alphas[0]*s1, alphas[1]*s2])\n",
    "fs = 16000\n",
    "for i in np.arange(n_sources):\n",
    "    d_stft = f1_f_delayed*(duet_mask==i).reshape(f1_f_delayed.shape)\n",
    "    gt_stft = f1_f_delayed*(gt_mask==i).reshape(f1_f_delayed.shape)\n",
    "    \n",
    "    \n",
    "    d_s_rec = librosa.core.istft( d_stft, \n",
    "                                 hop_length=hop_length, win_length=n_fft)\n",
    "    gt_s_rec = librosa.core.istft( gt_stft, \n",
    "                                 hop_length=hop_length, win_length=n_fft)\n",
    "\n",
    "    soundsc( d_s_rec, fs, 'Librosa Duet Reconstructed Signal for Source: {}'.format(i))\n",
    "    (sdr, sir, sar) = bss_eval( d_s_rec, 0, np.array(mics_sources[0]))\n",
    "    print((sdr, sir, sar))\n",
    "    (sdr, sir, sar) = bss_eval( d_s_rec, 1, np.array(mics_sources[0]))\n",
    "    print((sdr, sir, sar))\n",
    "    \n",
    "    soundsc( gt_s_rec, fs, 'Ground Truth Reconstructed Signal for Source: {}'.format(i))\n",
    "    (sdr, sir, sar) = bss_eval( gt_s_rec, 0, np.array(mics_sources[0]))\n",
    "    print((sdr, sir, sar))\n",
    "    (sdr, sir, sar) = bss_eval( gt_s_rec, 1, np.array(mics_sources[0]))\n",
    "    print((sdr, sir, sar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
